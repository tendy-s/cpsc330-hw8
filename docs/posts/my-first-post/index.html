<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Analysis of default of credit card clients dataset  | Tendy site</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Problem description In this mini project, our primary objective is to predict whether a credit card client will default (&ldquo;True&rdquo;) or not (&ldquo;False&rdquo;), which could potentially motivate the company to adopt appropriate preventative actions. This is often referred to as a binary classification spotting problem. In machine learning, calling &ldquo;score&rdquo; by default returns accuracy as a means to measure the quality of the model. However, in this particular problem, it would be beneficial to acquire an in-depth understanding of the errors.">
    <meta name="generator" content="Hugo 0.89.4" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
<link rel="stylesheet" href="/cpsc330-hw8/ananke/css/main.min.css" >




    
      

    

    
    
    <meta property="og:title" content="Analysis of default of credit card clients dataset " />
<meta property="og:description" content="Problem description In this mini project, our primary objective is to predict whether a credit card client will default (&ldquo;True&rdquo;) or not (&ldquo;False&rdquo;), which could potentially motivate the company to adopt appropriate preventative actions. This is often referred to as a binary classification spotting problem. In machine learning, calling &ldquo;score&rdquo; by default returns accuracy as a means to measure the quality of the model. However, in this particular problem, it would be beneficial to acquire an in-depth understanding of the errors." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tendy-s.github.io/cpsc330-hw8/posts/my-first-post/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-12-05T16:13:44-08:00" />
<meta property="article:modified_time" content="2021-12-05T16:13:44-08:00" />

<meta itemprop="name" content="Analysis of default of credit card clients dataset ">
<meta itemprop="description" content="Problem description In this mini project, our primary objective is to predict whether a credit card client will default (&ldquo;True&rdquo;) or not (&ldquo;False&rdquo;), which could potentially motivate the company to adopt appropriate preventative actions. This is often referred to as a binary classification spotting problem. In machine learning, calling &ldquo;score&rdquo; by default returns accuracy as a means to measure the quality of the model. However, in this particular problem, it would be beneficial to acquire an in-depth understanding of the errors."><meta itemprop="datePublished" content="2021-12-05T16:13:44-08:00" />
<meta itemprop="dateModified" content="2021-12-05T16:13:44-08:00" />
<meta itemprop="wordCount" content="906">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Analysis of default of credit card clients dataset "/>
<meta name="twitter:description" content="Problem description In this mini project, our primary objective is to predict whether a credit card client will default (&ldquo;True&rdquo;) or not (&ldquo;False&rdquo;), which could potentially motivate the company to adopt appropriate preventative actions. This is often referred to as a binary classification spotting problem. In machine learning, calling &ldquo;score&rdquo; by default returns accuracy as a means to measure the quality of the model. However, in this particular problem, it would be beneficial to acquire an in-depth understanding of the errors."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/cpsc330-hw8/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Tendy site
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>
    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Analysis of default of credit card clients dataset </h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2021-12-05T16:13:44-08:00">December 5, 2021</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><h3 id="problem-description">Problem description</h3>
<p>In this mini project, our primary objective is to predict whether a credit card client will default (&ldquo;True&rdquo;) or not (&ldquo;False&rdquo;), which could potentially motivate the company to adopt appropriate preventative actions. This is often referred to as a binary classification spotting problem. In machine learning, calling &ldquo;score&rdquo; by default returns accuracy as a means to measure the quality of the model. However, in this particular problem, it would be beneficial to acquire an in-depth understanding of the errors. For example, false positives (type I errors) is where the model incorrectly spots examples as &ldquo;will default&rdquo; and false negatives (type II errors) is where the model fails to spot &ldquo;will default&rdquo; examples. Since predicting &ldquo;True&rdquo; examples correctly is more important to us, recall (among all positive examples, how many did you identify?) and f1 score (a harmonic mean of precision and recall) may be more relevant than accuracy.</p>
<h3 id="description-of-the-dataset">Description of the dataset</h3>
<p>This dataset, known as the <a href="https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset">Default of Credit Card Clients Dataset</a>, contains 30,000 examples and 24 features (including our target column, which is labeled “default.payment.next.month”). Before conducting any machine learning, it is crucial to first split the data into a train set and a test set- this is critical for the training and validation phase, and ensures that we do not violate the golden rule of machine learning, which states that the test data cannot influence training the model in any way. We then perform exploratory analysis to acquire an understanding of what are potentially useful features.
It seems that for features education, marriage and pay_x, there are inconsistencies between the documentation and the actual data. For instance, there are 0&rsquo;s present in all three features but it&rsquo;s not clear what these represent. As we don&rsquo;t currently have access to the researchers, it&rsquo;s difficult to confirm. However, as indicated by a slightly darker blue colour, the heat map below (Figure 2) suggests there is a decent correlation between the pay_x features, education and our target; thus, it makes sense for these features to participate in the training phase of the model. We drop &ldquo;marriage&rdquo;, &ldquo;sex&rdquo; to avoid any biases in our model and &ldquo;id&rdquo; as they are unique identifiers and unlikely to serve a meaningful purpose. Finally, we see that class imbalance exists within the dataset (see Figure 1); this will influence how we might train our model in the next stage.</p>
<h4 id="figure-1-class-imbalance">Figure 1: Class imbalance</h4>
<p><img src="../img/class_imbalance.png" alt="class imbalance"></p>
<h4 id="figure-2-correlation-heatmap">Figure 2: Correlation Heatmap</h4>
<p><img src="../img/corr_heatmap.png" alt="correlation heatmap"></p>
<h3 id="description-of-the-model">Description of the model</h3>
<p>After making comparisons between a baseline and various appropriate classifiers, the chosen model was LightGBM. LightGBM is a gradient boosted tree model that is particularly notable for its speed. Since from our initial data analyses, we discovered that there is class imbalance, we address this issue by setting the class_weight to “balanced”. We further optimize its hyperparameters by using RandomizedSearchCV, which is a particularly useful method when we have many parameters to try. Through additional tuning, we are able to produce a slightly higher test f1 score of 0.544. Moreover, it is beneficial to evaluate which features our model considers to be important. For instance, by using a tool called shap, we are given an explanation of the impact of important features. In this case, the top three are pay_0, limit_bal and bill_amt1 (Figure 3).</p>
<h4 id="figure-3-randomsearchcv-with-lgbm-results">Figure 3: RandomSearchCV with LGBM results</h4>
<p><img src="../img/lgbm.png" alt="lgbm"></p>
<p><img src="../img/random_search.png" alt="random search"></p>
<h4 id="figure-4-feature-importance-using-shap">Figure 4: Feature importance using shap</h4>
<p><img src="../img/shap.png" alt="shap"></p>
<h3 id="results">Results</h3>
<p>To evaluate our results, we call score on the test set. Using the metric &ldquo;f1 score&rdquo;, our final test score is 0.53, which also agrees with the validation scores we obtained during the training phase (approximately 0.544). We trust our results, as we have a fairly large dataset, which means overfitting (which is when the model learns the detail and noise in the training data too well, thus negatively impacting its performance on new, unseen data) is less likely to be a concern and our test score is robust. Moreover, our recall for the class we are interested in (“True/Default&quot;) is fairly decent (0.62). This means that the business may be able to more effectively make decisions and perhaps send reminders to clients regarding timely payments or offer suitable alternatives. By improving the recall score, it could also provide a more objective means to determine whether an individual would be a responsible customer.
Below is a classification report that illustrates these relevant numbers (Figure 5).</p>
<p>Overall, this project serves as a solid foundation for any future exploration. Although the less relevant &ldquo;False/No default&rdquo; class seems to have achieved superior scores, we need to keep in mind that is very possible for our results to be further improved through other interesting techniques, such as feature engineering and adjusting prediction thresholds. But we’ll save these ideas for our next machine learning adventure!</p>
<h4 id="figure-5-classification-report">Figure 5: Classification report</h4>
<p><img src="../img/classification_report.png" alt="classification report"></p>
<h3 id="caveats">Caveats</h3>
<p>It is possible that our results may be misleading as we do not have access to the researchers responsible for assembling this dataset. Consequently, we may have misinterpreted how the features were encoded, which may have led us to prioritizing the wrong features. As illustrated in Figure X, it is also important to reiterate that class imbalance exists within this dataset. A mere 22% of the examples in the training set belong to the &ldquo;True&rdquo; class. While we have attempted to handle the imbalance through setting class_weight to &lsquo;balanced&rsquo;, there are potentially other more efficient methods to address this issue (e.g. through undersampling or oversampling, or making the weight of the positive class more important).</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://tendy-s.github.io/cpsc330-hw8" >
    &copy;  Tendy site 2021 
  </a>
    <div>
<div class="ananke-socials">
  
</div></div>
  </div>
</footer>

  </body>
</html>
